{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique data has been written to E:/xie/common_sensor_data.csv\n"
     ]
    }
   ],
   "source": [
    "# read the first row from the columns \"DetectorID\" and \"Location\" in a CSV file\n",
    "# for making the unique data from two directories - which is all sensor file list in 2018 and 2019\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def read_first_row(file_path):\n",
    "    \"\"\"\n",
    "    Read the first row from the columns \"DetectorID\" and \"Location\" in a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the \"DetectorID\" and \"Location\" from the first row.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        first_row = next(reader)\n",
    "        detector_id = first_row.get('DetectorID', '')\n",
    "        location = first_row.get('Location', '')\n",
    "    return detector_id, location\n",
    "\n",
    "def get_unique_data(directory1, directory2):\n",
    "    unique_data = set()\n",
    "    \n",
    "    for directory in [directory1, directory2]:\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.csv'):\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                detector_id, location = read_first_row(file_path)\n",
    "                if detector_id and location:  # Ensure both values are non-empty\n",
    "                    unique_data.add((detector_id, location))\n",
    "    \n",
    "    return unique_data\n",
    "\n",
    "def write_to_csv(data, output_file):\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['DetectorID', 'Location'])\n",
    "        for detector_id, location in data:\n",
    "            writer.writerow([detector_id, location])\n",
    "\n",
    "def main():\n",
    "    directory1 = 'E:/xie/Sensor Files/5. dataset/full MICE imputed datasets/2018'\n",
    "    directory2 = 'E:/xie/Sensor Files/5. dataset/full MICE imputed datasets/2019'\n",
    "    output_file = 'E:/xie/common_sensor_data.csv'\n",
    "\n",
    "    unique_data = get_unique_data(directory1, directory2)\n",
    "\n",
    "    write_to_csv(unique_data, output_file)\n",
    "\n",
    "    print(\"Unique data has been written to\", output_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append(row['DetectorID'])\n",
    "    return data\n",
    "\n",
    "def extract_sensor_parts(sensor_name, delimiter):\n",
    "    \"\"\"\n",
    "    Extracts sensor parts from a sensor name.\n",
    "\n",
    "    Args:\n",
    "        sensor_name (str): The sensor name.\n",
    "        delimiter (str): The delimiter used to separate parts.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the sensor parts.\n",
    "    \"\"\"\n",
    "    return tuple(sensor_name.split(delimiter))\n",
    "\n",
    "def compare_sensor_names(your_csv_file, chloes_csv_file):\n",
    "    sensor_names_file1 = read_csv(your_csv_file)\n",
    "    sensor_names_file2 = read_csv(chloes_csv_file)\n",
    "\n",
    "    # Extract sensor parts based on the delimiter used in each file\n",
    "    sensor_parts_file1 = [extract_sensor_parts(name, '.') for name in sensor_names_file1]\n",
    "    sensor_parts_file2 = [extract_sensor_parts(name, '_') for name in sensor_names_file2]\n",
    "\n",
    "    common_sensor_names = set(sensor_parts_file1) & set(sensor_parts_file2)\n",
    "    unique_sensor_names_file1 = set(sensor_parts_file1) - set(sensor_parts_file2)\n",
    "\n",
    "    return common_sensor_names, unique_sensor_names_file1\n",
    "\n",
    "def main():\n",
    "    your_csv_file = 'E:/xie/common_sensor_data.csv'\n",
    "    chloes_csv_file = 'E:/xie/Chloe - Reduced Detector Data - all_combined.csv'  # Provide the path to Chloe's CSV file\n",
    "\n",
    "    common_sensor_names, unique_sensor_names_file1 = compare_sensor_names(your_csv_file, chloes_csv_file)\n",
    "    \n",
    "    print(f\"Number of sensor names found in both files: {len(common_sensor_names)}\")\n",
    "    print(\"Common sensor names:\")\n",
    "    for sensor_parts in common_sensor_names:\n",
    "        sensor_name = '.'.join(sensor_parts)  # Join sensor parts with '.'\n",
    "        print(sensor_name)\n",
    "\n",
    "    print(f\"\\nNumber of sensor names found only in your file: {len(unique_sensor_names_file1)}\")\n",
    "    print(\"Sensor names found only in your file:\")\n",
    "    for sensor_parts in unique_sensor_names_file1:\n",
    "        sensor_name = '.'.join(sensor_parts)  # Join sensor parts with '.'\n",
    "        print(sensor_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding values for common sensor names have been saved to E:/xie/common_sensor_values.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def extract_sensor_parts(sensor_name, delimiter):\n",
    "    \"\"\"\n",
    "    Extracts sensor parts from a sensor name.\n",
    "\n",
    "    Args:\n",
    "        sensor_name (str): The sensor name.\n",
    "        delimiter (str): The delimiter used to separate parts.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the sensor parts.\n",
    "    \"\"\"\n",
    "    return tuple(sensor_name.split(delimiter))\n",
    "\n",
    "def compare_sensor_names(your_csv_file, chloes_csv_file):\n",
    "    sensor_names_file1 = read_csv(your_csv_file)\n",
    "    sensor_names_file2 = read_csv(chloes_csv_file)\n",
    "\n",
    "    # Extract sensor parts based on the delimiter used in each file\n",
    "    sensor_parts_file1 = {extract_sensor_parts(row['DetectorID'], '.') for row in sensor_names_file1}\n",
    "    sensor_parts_file2 = {extract_sensor_parts(row['DetectorID'], '_') for row in sensor_names_file2}\n",
    "\n",
    "    common_sensor_names = sensor_parts_file1 & sensor_parts_file2\n",
    "    unique_sensor_names_file1 = sensor_parts_file1 - sensor_parts_file2\n",
    "\n",
    "    # Find corresponding values for common sensor names\n",
    "    common_sensor_values = []\n",
    "    for sensor_name in common_sensor_names:\n",
    "        for row in sensor_names_file2:\n",
    "            if extract_sensor_parts(row['DetectorID'], '_') == sensor_name:\n",
    "                common_sensor_values.append(row)\n",
    "                break\n",
    "\n",
    "    return common_sensor_values, unique_sensor_names_file1\n",
    "\n",
    "def main():\n",
    "    your_csv_file = 'E:/xie/common_sensor_data.csv'\n",
    "    chloes_csv_file = 'E:/xie/Chloe - Reduced Detector Data - all_combined.csv'  # Provide the path to Chloe's CSV file\n",
    "\n",
    "    common_sensor_values, unique_sensor_names_file1 = compare_sensor_names(your_csv_file, chloes_csv_file)\n",
    "\n",
    "    # Save corresponding values for common sensor names to a new CSV file\n",
    "    output_file = 'E:/xie/common_sensor_values.csv'\n",
    "    fieldnames = ['DetectorID', 'Location', 'Latitude', 'Longitude']\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in common_sensor_values:\n",
    "            writer.writerow({'DetectorID': row['DetectorID'], 'Location': row['Location'], 'Latitude': row['Latitude'], 'Longitude': row['Longitude']})\n",
    "\n",
    "    print(f\"Corresponding values for common sensor names have been saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'road1': 'I-215 SB TownCenter OnRamp', 'road2': 'Sahara Avenue and I-515 SB to Lake Mead Dr', 'location_type': 'OnRamp', 'direction': 'Southbound'}\n"
     ]
    }
   ],
   "source": [
    "def parse_location_description(description):\n",
    "    \"\"\"\n",
    "    Parse a location description and extract relevant information.\n",
    "\n",
    "    Args:\n",
    "        description (str): The location description.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing parsed information.\n",
    "    \"\"\"\n",
    "    parsed_info = {}\n",
    "\n",
    "    # Split the description by 'between' to separate road names\n",
    "    parts = description.split('between')\n",
    "\n",
    "    # Extract road names\n",
    "    if len(parts) == 2:\n",
    "        road_names = [part.strip() for part in parts]\n",
    "        parsed_info['road1'] = road_names[0]\n",
    "        parsed_info['road2'] = road_names[1]\n",
    "\n",
    "    # Extract direction and on-ramp/off-ramp information\n",
    "    if 'OnRamp' in description:\n",
    "        parsed_info['location_type'] = 'OnRamp'\n",
    "        if 'SB' in description:\n",
    "            parsed_info['direction'] = 'Southbound'\n",
    "        elif 'NB' in description:\n",
    "            parsed_info['direction'] = 'Northbound'\n",
    "    elif 'OffRamp' in description:\n",
    "        parsed_info['location_type'] = 'OffRamp'\n",
    "        if 'SB' in description:\n",
    "            parsed_info['direction'] = 'Southbound'\n",
    "        elif 'NB' in description:\n",
    "            parsed_info['direction'] = 'Northbound'\n",
    "\n",
    "    return parsed_info\n",
    "\n",
    "# Example usage:\n",
    "description = \"I-215 SB TownCenter OnRamp between Sahara Avenue and I-515 SB to Lake Mead Dr\"\n",
    "parsed_info = parse_location_description(description)\n",
    "print(parsed_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'highway': 'I-215', 'direction': 'SB', 'ramp_type': 'OnRamp', 'segment': {'start': 'Sahara Avenue', 'end': 'I'}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_location_description(description):\n",
    "    \"\"\"\n",
    "    Parse a location description and extract relevant information.\n",
    "\n",
    "    Args:\n",
    "        description (str): The location description.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing parsed information.\n",
    "    \"\"\"\n",
    "    parsed_info = {}\n",
    "\n",
    "    # Define regular expressions to match different components\n",
    "    highway_pattern = r'(I-\\d{3}|US-\\d{2}|CC-\\d{3})'  # Matches highway names like I-15, US-95, CC-215\n",
    "    direction_pattern = r'(NB|SB|EB|WB)'  # Matches directions like Northbound, Southbound, Eastbound, Westbound\n",
    "    ramp_pattern = r'(OnRamp|OffRamp)'  # Matches on-ramp or off-ramp\n",
    "    segment_pattern = r'between\\s([\\w\\s]+?)\\s+and\\s+([\\w\\s]+)'  # Matches road segments between two points\n",
    "\n",
    "    # Extract highway name\n",
    "    highway_match = re.search(highway_pattern, description)\n",
    "    if highway_match:\n",
    "        parsed_info['highway'] = highway_match.group(0)\n",
    "\n",
    "    # Extract direction\n",
    "    direction_match = re.search(direction_pattern, description)\n",
    "    if direction_match:\n",
    "        parsed_info['direction'] = direction_match.group(0)\n",
    "\n",
    "    # Extract ramp type\n",
    "    ramp_match = re.search(ramp_pattern, description)\n",
    "    if ramp_match:\n",
    "        parsed_info['ramp_type'] = ramp_match.group(0)\n",
    "\n",
    "    # Extract road segment\n",
    "    segment_match = re.search(segment_pattern, description)\n",
    "    if segment_match:\n",
    "        parsed_info['segment'] = {\n",
    "            'start': segment_match.group(1),\n",
    "            'end': segment_match.group(2)\n",
    "        }\n",
    "\n",
    "    return parsed_info\n",
    "\n",
    "# Example usage:\n",
    "description = \"I-215 SB TownCenter OnRamp between Sahara Avenue and I-515 SB to Lake Mead Dr\"\n",
    "parsed_info = parse_location_description(description)\n",
    "print(parsed_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'highway': 'I-215', 'direction': 'SB', 'segment': {'start': 'Sahara Avenue', 'end': 'I'}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_location_description(description):\n",
    "    \"\"\"\n",
    "    Parse a location description and extract relevant information.\n",
    "\n",
    "    Args:\n",
    "        description (str): The location description.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing parsed information.\n",
    "    \"\"\"\n",
    "    parsed_info = {}\n",
    "\n",
    "    # Define regular expressions to match different components\n",
    "    highway_pattern = r'(I-\\d{3}|US-\\d{2}|CC-\\d{3})'  # Matches highway names like I-15, US-95, CC-215\n",
    "    direction_pattern = r'(NB|SB|EB|WB)'  # Matches directions like Northbound, Southbound, Eastbound, Westbound\n",
    "    ramp_pattern = r'(OnRamp|OffRamp)'  # Matches on-ramp or off-ramp\n",
    "    segment_pattern = r'between\\s([\\w\\s]+?)\\s+and\\s+([\\w\\s]+)'  # Matches road segments between two points\n",
    "\n",
    "    # Extract highway name\n",
    "    highway_match = re.search(highway_pattern, description)\n",
    "    if highway_match:\n",
    "        parsed_info['highway'] = highway_match.group(0)\n",
    "\n",
    "    # Extract direction\n",
    "    direction_match = re.search(direction_pattern, description)\n",
    "    if direction_match:\n",
    "        parsed_info['direction'] = direction_match.group(0)\n",
    "\n",
    "    # Extract ramp type if not in description\n",
    "    if 'onramp' not in description.lower() and 'offramp' not in description.lower():\n",
    "        ramp_match = re.search(ramp_pattern, description)\n",
    "        if ramp_match:\n",
    "            parsed_info['ramp_type'] = ramp_match.group(0)\n",
    "\n",
    "    # Extract road segment\n",
    "    segment_match = re.search(segment_pattern, description)\n",
    "    if segment_match:\n",
    "        parsed_info['segment'] = {\n",
    "            'start': segment_match.group(1),\n",
    "            'end': segment_match.group(2)\n",
    "        }\n",
    "\n",
    "    return parsed_info\n",
    "\n",
    "# Example usage:\n",
    "description = \"I-215 SB TownCenter OnRamp between Sahara Avenue and I-515 SB to Lake Mead Dr\"\n",
    "parsed_info = parse_location_description(description)\n",
    "print(parsed_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a csv and save the first column as a separte csv\n",
    "import csv  \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
