{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import miceforest as mf\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number io files with more than 70% non-NaN values in column 4\n",
    "def count_non_nan_values(directory):\n",
    "    # Initialize counter for files with more than 70 non-NaN values in column 4\n",
    "    count = 0\n",
    "    \n",
    "    # Iterate over each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Count non-NaN values in column 4\n",
    "            non_nan_count = df.iloc[:, 3].count()  # Assuming column 4 is indexed at 3 (0-based index)\n",
    "            #print(non_nan_count)\n",
    "            percentage=non_nan_count/35040 *100\n",
    "            # Check if the count exceeds 70\n",
    "            if percentage > 70:\n",
    "                count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Directory containing CSV files\n",
    "directory = 'E:/xie/Sensor Files/3. filled w empty rows - fixed to 35040 rows/2019'\n",
    "\n",
    "# Call the function to count files with more than 70 non-NaN values in column 4\n",
    "result = count_non_nan_values(directory)\n",
    "print(f\"Number of files with more than 70% non-NaN values in column 4: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using MICE algorithm\n",
    "# Scan CSV files in input directory\n",
    "# For each file:\n",
    "#   If >70% rows filled:\n",
    "#     Impute missing values with MICE\n",
    "#     Save imputed dataset to output directory\n",
    "# Print status messages\n",
    "\n",
    "\n",
    "def impute_missing_values(input_directory, output_directory):\n",
    "    # Get all CSV files in the input directory\n",
    "    file_paths = [os.path.join(input_directory, filename) for filename in os.listdir(input_directory) if filename.endswith('.csv')]\n",
    "    \n",
    "    # Process each CSV file\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        total_rows = 35040\n",
    "        non_nan_count = df.iloc[:, 3].count()\n",
    "        rows_with_data = non_nan_count\n",
    "        \n",
    "        # Calculate the percentage of filled rows\n",
    "        filled_rows_percentage = (rows_with_data / total_rows) * 100.0\n",
    "        \n",
    "        # If less than 70 percent rows are available, skip imputation for this file\n",
    "        if filled_rows_percentage < 70:\n",
    "            print(f\"Skipping imputation for '{file_path}'\")\n",
    "        else:\n",
    "            # Convert DataFrame to numpy array\n",
    "            data_array = df.drop(columns=['DateTimeStamp']).values\n",
    "        \n",
    "            # Create kernel\n",
    "            kds = mf.ImputationKernel(data_array, save_all_iterations=True, random_state=1991)\n",
    "        \n",
    "            # Run the MICE algorithm for 15 iterations\n",
    "            kds.mice(15)\n",
    "        \n",
    "            # Return the completed dataset\n",
    "            completed_data = kds.complete_data()\n",
    "        \n",
    "            # Convert completed data back to DataFrame\n",
    "            completed_df = pd.DataFrame(completed_data, columns=df.columns[1:])\n",
    "            completed_df.insert(0, 'DateTimeStamp', df['DateTimeStamp'])\n",
    "        \n",
    "            # Replace '_emptyrows' with '_impute' in the output file name\n",
    "            output_file_name = os.path.basename(file_path).replace('_emptyrows', '_impute')\n",
    "        \n",
    "            # Save the completed dataset to the output directory\n",
    "            output_file_path = os.path.join(output_directory, output_file_name)\n",
    "            completed_df.to_csv(output_file_path, index=False)\n",
    "            print(f\"Imputed values saved to '{output_file_path}'.\")\n",
    "\n",
    "# Input and output directory paths\n",
    "input_directory = 'E:/xie/Sensor Files/3. filled w empty rows - fixed to 35040 rows/2018'\n",
    "output_directory = 'E:/xie/Sensor Files/4. impute/full MICE imputated/2018'\n",
    "\n",
    "# Call the function\n",
    "impute_missing_values(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "This script fills missing values in CSV files with either 0 or -1 based on user preference. It processes each CSV file in the input directory, checks the percentage of filled rows, and if it meets the specified threshold, it fills missing values with the chosen value (0 or -1) and saves the completed datasets to the output directory.\n",
    "\n",
    "Parameters:\n",
    "- input_directory: The directory containing CSV files with missing values.\n",
    "- output_directory: The directory where completed datasets will be saved after filling missing values.\n",
    "- fill_value: The value used to fill missing values. Can be either 0 or -1.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def fill_missing_values(input_directory, output_directory, fill_value):\n",
    "    # Get all CSV files in the input directory\n",
    "    file_paths = [os.path.join(input_directory, filename) for filename in os.listdir(input_directory) if filename.endswith('.csv')]\n",
    "    \n",
    "    # Process each CSV file\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        total_rows = 35040\n",
    "        non_nan_count = df.iloc[:, 3].count()\n",
    "        rows_with_data = non_nan_count\n",
    "        \n",
    "        # Calculate the percentage of filled rows\n",
    "        filled_rows_percentage = (rows_with_data / total_rows) * 100.0\n",
    "        \n",
    "        # If less than 70 percent rows are available, skip filling for this file\n",
    "        if filled_rows_percentage < 70:\n",
    "            print(f\"Skipping filling for '{file_path}'\")\n",
    "        else:\n",
    "            # Fill missing values with the specified fill value\n",
    "            filled_df = df.fillna(fill_value)\n",
    "        \n",
    "            # Replace '_emptyrows' with '_filled' in the output file name\n",
    "            output_file_name = os.path.basename(file_path).replace('_emptyrows', '_filled')\n",
    "        \n",
    "            # Save the filled dataset to the output directory\n",
    "            output_file_path = os.path.join(output_directory, output_file_name)\n",
    "            filled_df.to_csv(output_file_path, index=False)\n",
    "            print(f\"Filled values saved to '{output_file_path}'.\")\n",
    "\n",
    "# Input and output directory paths\n",
    "input_directory = 'E:/xie/Sensor Files/3. filled w empty rows - fixed to 35040 rows/2018'\n",
    "output_directory = 'E:/xie/Sensor Files/4. impute/full -1 imputated/2018'\n",
    "\n",
    "# Specify the fill value (0 or -1)\n",
    "fill_value = -1  # Change this to -1 if desired\n",
    "\n",
    "# Call the function\n",
    "fill_missing_values(input_directory, output_directory, fill_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common CSV files copied successfully.\n"
     ]
    }
   ],
   "source": [
    "# get common data files from both years and copy them to the destination folders\n",
    "\n",
    "def get_common_csv_files(folder1, folder2):\n",
    "    files_folder1 = set(file for file in os.listdir(folder1) if file.endswith('.csv'))\n",
    "    files_folder2 = set(file for file in os.listdir(folder2) if file.endswith('.csv'))\n",
    "    \n",
    "    common_files = files_folder1.intersection(files_folder2)\n",
    "    return common_files\n",
    "\n",
    "def copy_files(source_folder, destination_folder, files_to_copy):\n",
    "    for file in files_to_copy:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(destination_folder, file)\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "\n",
    "# Replace these paths with your actual paths\n",
    "folder1_path = 'E:/xie/Sensor Files/4. impute/full -1 imputated/2018'\n",
    "folder2_path = 'E:/xie/Sensor Files/4. impute/full -1 imputated/2019'\n",
    "destination_folder1_path = 'E:/xie/Sensor Files/4. impute/full -1 imputated Common Files/2018'\n",
    "destination_folder2_path = 'E:/xie/Sensor Files/4. impute/full -1 imputated Common Files/2019'\n",
    "\n",
    "common_files = get_common_csv_files(folder1_path, folder2_path)\n",
    "\n",
    "# Copy common files to destination folders\n",
    "copy_files(folder1_path, destination_folder1_path, common_files)\n",
    "copy_files(folder2_path, destination_folder2_path, common_files)\n",
    "\n",
    "print(\"Common CSV files copied successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
